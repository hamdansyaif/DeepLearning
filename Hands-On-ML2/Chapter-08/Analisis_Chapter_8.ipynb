{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJPZlZSoJbtvOmh7moepsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamdansyaif/DeepLearning/blob/main/Hands-On-ML2/Chapter-08/Analisis_Chapter_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# 📘 **Rekap Teori & Analisis Lengkap – Chapter 8: Dimensionality Reduction**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚩 **Tujuan Reduksi Dimensi**\n",
        "\n",
        "Reduksi dimensi dilakukan untuk:\n",
        "\n",
        "* 🔧 Menurunkan kompleksitas data\n",
        "* 💾 Mengurangi kebutuhan penyimpanan\n",
        "* ⚡ Meningkatkan performa model\n",
        "* 👁️‍🗨️ Memvisualisasikan data tinggi ke dimensi rendah\n",
        "\n",
        "---\n",
        "\n",
        "## 🔷 **1. Manual PCA via SVD (Singular Value Decomposition)**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* PCA mencari arah (vektor) baru yang menjelaskan varian data terbesar.\n",
        "* Langkah:\n",
        "\n",
        "  1. Center data (mean=0)\n",
        "  2. Gunakan SVD → hasilkan Vᵀ (eigenvektor)\n",
        "  3. Proyeksikan data ke beberapa vektor utama\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "* Dataset 3D buatan → `np.linalg.svd`\n",
        "* Ambil `Vt.T[:, :2]` → proyeksi ke 2D\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* MSE rekonstruksi rendah → PCA efektif\n",
        "* Komponen utama (PC1 & PC2) berhasil menangkap mayoritas informasi\n",
        "* Visualisasi menunjukkan arah PC1 dan PC2 pada data 3D (✔️ visual fig 8–2 & fig 8–3)\n",
        "\n",
        "---\n",
        "\n",
        "## 🔶 **2. PCA dengan Scikit-Learn**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* `PCA(n_components=k)` otomatis:\n",
        "\n",
        "  * Center data\n",
        "  * Gunakan SVD internal\n",
        "  * Transform dan inverse transform data\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "```python\n",
        "pca = PCA(n_components=2)\n",
        "X_2d = pca.fit_transform(X_centered)\n",
        "```\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Korelasi tinggi dengan versi manual (±1)\n",
        "* Lebih efisien dan bisa langsung `.inverse_transform` untuk rekonstruksi\n",
        "* Cocok untuk pipeline produksi\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 **3. Explained Variance & Elbow Curve**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* `explained_variance_ratio_` menunjukkan proporsi varian yang dijelaskan tiap PC\n",
        "* `np.cumsum(...)` digunakan untuk menentukan jumlah komponen optimal\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "* Elbow plot visual\n",
        "* Cari jumlah komponen ≥ 95% variansi → `argmax(cumsum >= 0.95) + 1`\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Threshold 95% sering digunakan sebagai titik optimal\n",
        "* PCA ≈ lossy compression, tapi tetap menjaga struktur penting\n",
        "\n",
        "---\n",
        "\n",
        "## 🔤 **4. PCA pada Dataset MNIST (784 ➜ \\~150 komponen)**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* Dataset gambar bisa direpresentasikan dalam dimensi lebih rendah tanpa kehilangan makna visual\n",
        "* PCA cocok untuk kompresi dan persiapan klasifikasi/clustering\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "* `PCA(n_components=...)` → reduksi MNIST\n",
        "* `inverse_transform` → bandingkan gambar asli vs hasil kompresi\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Gambar masih dapat dikenali\n",
        "* \\~150 komponen cukup menjelaskan ≥95% informasi\n",
        "\n",
        "---\n",
        "\n",
        "## 🧿 **5. Visualisasi PCA 2D MNIST**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* PCA bisa digunakan untuk visualisasi distribusi data dalam 2D\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "* Scatter plot tiap digit → `plt.scatter(X_pca[:,0], X_pca[:,1])`\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Terlihat ada klaster digit meskipun sebagian overlap\n",
        "* PCA linear → tidak selalu memisahkan klaster dengan jelas\n",
        "\n",
        "---\n",
        "\n",
        "## ♻️ **6. Incremental PCA (Mini-Batch)**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* Cocok untuk dataset besar (streaming atau tidak muat RAM)\n",
        "* Dilatih secara batch dengan `.partial_fit()`\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "```python\n",
        "ipca = IncrementalPCA(n_components=..., batch_size=...)\n",
        "ipca.partial_fit(X_batch)\n",
        "```\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Rekonstruksi mirip dengan PCA biasa\n",
        "* Efisien untuk big data / edge devices\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 **7. Simulasi Incremental PCA untuk Dataset Besar**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* Gunakan generator/data chunk untuk simulasi data besar\n",
        "* Proses batch-by-batch untuk PCA streaming\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "* `make_classification()` + `data_generator()` + `partial_fit`\n",
        "* Visualisasi explained variance dan proyeksi 2D (sample batch)\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Incremental PCA tetap bisa menjaga variansi dominan\n",
        "* Visualisasi 2D tetap menunjukkan distribusi yang masuk akal\n",
        "\n",
        "---\n",
        "\n",
        "## 🌐 **8. t-SNE (Non-Linear Projection)**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* Menjaga hubungan **lokal** antar data\n",
        "* Cocok untuk **visualisasi klaster non-linear**\n",
        "* Tidak bisa `.transform()` data baru\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "```python\n",
        "TSNE(n_components=2, perplexity=30, max_iter=1000).fit_transform(X)\n",
        "```\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Klaster digit MNIST sangat jelas → cocok untuk interpretasi visual\n",
        "* Performa lambat, hanya untuk visualisasi\n",
        "\n",
        "---\n",
        "\n",
        "## 🌀 **9. LLE (Locally Linear Embedding)**\n",
        "\n",
        "### 📌 *Teori:*\n",
        "\n",
        "* Menjaga representasi lokal via kombinasi linier tetangga\n",
        "* Berguna untuk data di manifold non-linear (misalnya permukaan melengkung)\n",
        "\n",
        "### 📦 *Kode:*\n",
        "\n",
        "```python\n",
        "LocallyLinearEmbedding(n_components=2, n_neighbors=10).fit_transform(X)\n",
        "```\n",
        "\n",
        "### 🧠 *Analisis:*\n",
        "\n",
        "* Struktur manifold terlihat\n",
        "* Tidak bisa `.transform()` → bukan untuk prediksi\n",
        "\n",
        "---\n",
        "\n",
        "# ✅ **Kesimpulan Akhir – Kapan Pakai Apa**\n",
        "\n",
        "| Teknik          | Gunakan Saat...                      | Bisa Transform Baru? | Visualisasi Bagus? |\n",
        "| --------------- | ------------------------------------ | -------------------- | ------------------ |\n",
        "| PCA             | Linear, cepat, umum digunakan        | ✅                    | ✅ (terbatas)       |\n",
        "| Incremental PCA | Dataset sangat besar / batch-wise    | ✅                    | ✅ (opsional)       |\n",
        "| t-SNE           | Ingin lihat klaster secara visual    | ❌                    | ✅✅                 |\n",
        "| LLE             | Data punya struktur lokal non-linear | ❌                    | ✅                  |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wi6k8O3gD2Zl"
      }
    }
  ]
}